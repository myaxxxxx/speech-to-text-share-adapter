






<h2 align="center">
Parameter-Efficient Adapters Based on Pre-trained Models for Speech Translation
</h2>

<p align="center">
  <!-- <img src="https://img.shields.io/badge/EMNLP-2023-brightgreen"> -->
  <!-- <under review><img src="http://img.shields.io/badge/Paper-PDF-red.svg"></a> -->
  <img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg">
  <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?e&logo=PyTorch&logoColor=white">
</p>

<p align="center">
 Codes for our regular and share adapters for speech-to-text translation tasks (Under review). 
</p>


### Installation

1. Create a conda environment with Pytorch:

```
conda create --name adapters python=3.9
source activate adapters
```

2. Install fairseq

```bash
git clone https://github.com/pytorch/fairseq
cd fairseq
pip install --editable ./
# or install fairseq from the current dir
pip install --editable ./

# Next: Important!
python setup.py build develop


```

3. Other operations

Due to the version compatibility of packages, you also need to reinstall the following packages：

```bash
# numpy np.float error 
pip install numpy==1.23.5

# generation error: sacrebleu import error TOKENIZER 
pip install sacrebleu==1.5.1
```

### Datasets and Models

<!-- #### Mustc v1 -->

Due to the anonymous Github upload space limitation, we currently only upload the test set. After the double-blind review period, we will publish the Fairseq Databin file on Google Drive.

1.  Download [Vocabulary](https://deltalm.blob.core.windows.net/deltalm/dict.txt) and [ Sentencepiece-model](https://deltalm.blob.core.windows.net/deltalm/spm.model) of deltalm and you need to tokenize raw data to spm data. 
2.  Preprocess spm data. 

WMT preprocess

```

ROOT=/data/translation/ted_8_diverse_spm
DICT=$ROOT/dict.txt
DATA_BIN=/data/translation/ted_8_diverse_o2m
RAW_DATA=$ROOT

# for lang in "bos" "mar" "hin" "mkd" "ell" "bul" "fra" "kor";

for item in "bos" "mar" "hin" "mkd" "ell" "bul" "fra" "kor";

do 
echo $item

fairseq-preprocess  \
    --trainpref $RAW_DATA/train.$item-eng \
    --testpref $RAW_DATA/valid.$item-eng \
    --validpref $RAW_DATA/test.$item-eng \
    --source-lang eng  --target-lang $item \
    --destdir $DATA_BIN \
    --srcdict $DICT \
    --tgtdict $DICT \
    --workers 40

done
```

### Training

```
```


#### Machine Translation Pre-train


#### ASR Pre-train



#### Speeech-to-text Translation Training


### Evaluation

In order to reproduce the results of our paper,  run the following commands:

En-Ro

```


lang_pairs="bos-eng,mar-eng,hin-eng,mkd-eng,ell-eng,bul-eng,fra-eng,kor-eng"


path_2_data=/path/to/data
lang_list=${path_2_data}/lang_list_diverse.txt
SAVE_DIR=/path/to/save
USER_DIR=adapter_deltalm

PRETRAINED_MODEL=/path/to/pretrain_model/deltalm-base.pt
mkdir -vp $SAVE_DIR

export CUDA_VISIBLE_DEVICES=0,1,2,3

python train.py $path_2_data \
    --arch deltalm_base  \
    --user-dir $USER_DIR \
    --encoder-normalize-before --decoder-normalize-before \
    --pretrained-deltalm-checkpoint $PRETRAINED_MODEL \
    --share-all-embeddings \
    --max-source-positions 512 --max-target-positions 512 \
    --task translation_multi_simple_epoch \
    --sampling-method "temperature" \
    --sampling-temperature 5 \
    --decoder-langtok \
    --encoder-langtok "src" \
    --lang-dict "$lang_list" \
    --lang-pairs "$lang_pairs" \
    --criterion label_smoothed_cross_entropy \
    --label-smoothing 0.1 \
    --optimizer adam --adam-betas '(0.9, 0.98)' \
    --lr-scheduler inverse_sqrt \
    --lr 8e-5 \
    --warmup-init-lr 1e-07 \
    --stop-min-lr 1e-09 \
    --warmup-updates 6000 \
    --max-update 400000 \
    --max-epoch 50 \
    --max-tokens 8000 \
    --update-freq 1 \
    --seed 1 \
    --skip-invalid-size-inputs-valid-test \
    --tensorboard-logdir $SAVE_DIR/tensorboard \
    --save-dir $SAVE_DIR/checkpoints \
    --keep-last-epochs 50 \
    --fp16 --adapters-bottle 128

# for o2m, you can set --encoder-langtok "tgt" for original m2o data-bin file.
```

### Evaluation

Diverse M2O

```
checkpoint_path=$SAVE_DIR/checkpoints

OUTPUT_DIR=$checkpoint_path/$i

mkdir -p $OUTPUT_DIR

model=${checkpoint_path}/checkpoint$i.pt
echo "model: ${model}"
for tgt in eng; do
    for src in bos mar hin mkd ell bul fra kor; do
        python generate.py $path_2_data \
            --path $model \
            --user-dir $USER_DIR \
            --task translation_multi_simple_epoch \
            --lang-dict "$lang_list" \
            --lang-pairs "$lang_pairs" \
            --gen-subset test \
            --source-lang $src \
            --target-lang $tgt \
            --encoder-langtok "src" \
            --scoring sacrebleu \
            --remove-bpe 'sentencepiece'\
            --batch-size 96 \
            --decoder-langtok > $OUTPUT_DIR/test_${src}_${tgt}.txt 2>&1

    done
done

# for o2m, you can set --encoder-langtok "tgt" for original m2o data-bin file.
```

### NAS-inspired

For training convenience, we add a regular adapter to each layer of the multilingual pre-training model and store parameters weight_A and weight_B in the regular adapter. After the first stage of training, we count the weight_A and weight_B to get the weights_list. we then perform the following calculations in the second stage:

```

encoder_list = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1,1,1 ]

x1 = self.adapters[index](x)
x2 = self.share_adapter(x)

weights_softmax = nn.Softmax(dim=-1)
weights_adapter = weights_softmax(torch.cat((self.adapters[index].weight_A, self.adapters[index].weight_B)))
x = (1- share_list[index]) * x1 * weights_adapter[0] + share_list[index] * x2 * weights_adapter[1]

## decoder_list is similar to encoder
```

After getting the optimal architecture, we design the corresponding specific model and migrate the parameters.


### Acknowledgement

We refer to the code of [Deltalm](https://github.com/microsoft/unilm/tree/master/deltalm) and [CRESS](https://github.com/ictnlp/CRESS). Thanks for their great contributions!
